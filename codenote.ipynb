{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T05:51:55.277179Z","iopub.status.busy":"2022-03-22T05:51:55.276837Z","iopub.status.idle":"2022-03-22T05:51:55.296837Z","shell.execute_reply":"2022-03-22T05:51:55.295664Z","shell.execute_reply.started":"2022-03-22T05:51:55.277143Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.nn import functional as F\n","import torchvision\n","from torchvision import transforms\n","from torch.utils import data\n","from tqdm import tqdm\n","from IPython import display\n","import matplotlib.pyplot as plt\n","import sys\n","import utils\n","# sys.path.append('/kaggle/input')\n","# from myutils import utils"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["class Inception (nn.Module):\n","    def __init__(self, in_channels, c1, c2, c3, c4, **kwargs):\n","        super(Inception, self).__init__(**kwargs)\n","        #第一条线路\n","        self.conv1 = nn.Conv2d(in_channels, c1, kernel_size=1)\n","        #第二条线路\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(in_channels, c2[0], kernel_size=1), nn.ReLU(),\n","            nn.Conv2d(c2[0], c2[1], kernel_size=3,padding=1), nn.ReLU()\n","        )\n","        #第三条线路\n","        self.conv3 = nn.Sequential(\n","            nn.Conv2d(in_channels, c3[0], kernel_size=1), nn.ReLU(),\n","            nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2), nn.ReLU()\n","        )\n","        #第四条线路\n","        self.conv4 = nn.Sequential(\n","            nn.MaxPool2d(kernel_size=3,stride=1, padding=1), nn.ReLU(),\n","            nn.Conv2d(in_channels, c4, kernel_size=1), nn.ReLU()\n","        )\n","\n","    def forward(self, x):\n","        return torch.cat((\n","            self.conv1(x),\n","            self.conv2(x),\n","            self.conv3(x),\n","            self.conv4(x)\n","            ), dim = 1)\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["class Residual (nn.Module):\n","    def __init__(self, input_channels, num_channels, strides, use_1x1conv=False):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(input_channels, num_channels, kernel_size=3, padding=1, stride=strides)\n","        self.conv2 = nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1)\n","        if use_1x1conv :\n","            self.conv3 = nn.Conv2d(input_channels, num_channels, kernel_size=1, stride=strides)\n","        else:\n","            self.conv3 = None\n","        self.bn1 = nn.BatchNorm2d(num_channels)\n","        self.bn2 = nn.BatchNorm2d(num_channels)\n","    def forward (self, X):\n","        \n","\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_ch6(net , train_iter, test_iter, num_epochs, lr, device):\n","    def init_weight(m):\n","        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n","            nn.init.xavier_uniform_(m.weight)\n","    net.apply(init_weight)\n","    net.to(device)\n","    print('training on', device)\n","    loss = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n","    for epoch in tqdm(range(num_epochs)):\n","        net.train()\n","        metric = utils.Accumulator(2)\n","        for i, (X, y) in enumerate(train_iter):\n","            optimizer.zero_grad()\n","            X, y = X.to(device), y.to(device)\n","            l = loss(net(X), y)\n","            l.backward()\n","            optimizer.step()\n","        print(l)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":4}
